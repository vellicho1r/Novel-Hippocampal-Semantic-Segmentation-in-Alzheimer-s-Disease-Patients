{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1.1. Install Essentials**"
      ],
      "metadata": {
        "id": "4_5GcStPZi6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output    #Because of the Error : NameError: name 'clear_output' is not defined"
      ],
      "metadata": {
        "id": "rGeZyF2RUp5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons\n",
        "!pip install keras\n",
        "!pip install segmentation-models\n",
        "!pip install tf_explain\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "yhVSUjrnaBUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2. Import Essentials**"
      ],
      "metadata": {
        "id": "spNXPV6Earyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Because of the Error AttributeError: module 'keras.utils' has no attribute 'generic_utils'\n",
        "\n",
        "!pip install -U -q segmentation-models\n",
        "!pip install -q tensorflow==2.2.1\n",
        "!pip install -q keras==2.5\n",
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "from tensorflow import keras\n",
        "import segmentation_models as sm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mOvRlZc9VAq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nibabel\n",
        "!pip install segmentation-models\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda, Activation\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "from segmentation_models.losses import bce_jaccard_loss\n",
        "from segmentation_models.losses import bce_dice_loss\n",
        "from segmentation_models.losses import binary_focal_dice_loss\n",
        "from keras.losses import binary_crossentropy\n",
        "#from keras.losses import dice_ce\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "#from res_unet_model import multi_unet_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import pathlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iPchVVf-lqTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3. Drive Mount Dataset : Nifti images + Nifti masks**"
      ],
      "metadata": {
        "id": "mRSHyR0yZtr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from skimage.transform import resize\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "S8zHgxaMVlPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image, SIZE):\n",
        "    return np.round(resize(img_to_array(load_img(image))/255.,(SIZE, SIZE)),4)"
      ],
      "metadata": {
        "id": "SjVbDciuVpE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(image_paths, SIZE, mask=False, trim=None):\n",
        "    if trim is not None:\n",
        "        image_paths = image_paths[:trim]\n",
        "\n",
        "    if mask:\n",
        "        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 1))\n",
        "    else:\n",
        "        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 3))\n",
        "\n",
        "    for i,image in enumerate(image_paths):\n",
        "        img = load_image(image,SIZE)\n",
        "        if mask:\n",
        "            images[i] = img[:,:,:1]\n",
        "        else:\n",
        "            images[i] = img\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "ZDsSFNf8BJ6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_mask_only(mask, cmap=None, alpha=0.4):\n",
        "    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "vES1PEWso9kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4. Import NifTi Data**"
      ],
      "metadata": {
        "id": "jku59_L8Z5qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2ZJI9LTKSHzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/HarP'\n",
        "path_dir = pathlib.Path('/content/drive/MyDrive/imageandsegment/')\n",
        "\n",
        "class_names = np.array(sorted([item.name for item in path_dir.glob('*')]))\n",
        "print(class_names)\n",
        "IMAGE_SIZE= (256,256)\n",
        "import glob   #Because of the Error : function has no Attribute glob\n",
        "\n",
        "image_paths = sorted(glob.glob(('/content/drive/MyDrive/imageandsegment/training/image/*')))\n",
        "mask_paths = sorted(glob.glob(('/content/drive/MyDrive/imageandsegment/training/mask/*')))"
      ],
      "metadata": {
        "id": "s_k4ZB7sXO6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Approximate Running time = 4min"
      ],
      "metadata": {
        "id": "A_9xEq56YRwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 256"
      ],
      "metadata": {
        "id": "c8Hl7jgRc2Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = load_images(image_paths, SIZE)\n",
        "masks = load_images(mask_paths, SIZE, mask=True)"
      ],
      "metadata": {
        "id": "g7m9GEbaXe90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1. Defining Attention UNet for Semantic Segmentation ----> Encoder Part**"
      ],
      "metadata": {
        "id": "q_G0maCscznG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer   #Because of the error : NameError: name 'Layer' is not defined"
      ],
      "metadata": {
        "id": "YerceC3QYa_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback    #Because Callback was not defined\n",
        "\n",
        "from keras.layers import Add    #Because of the NameError : name 'Add' is not defined\n",
        "\n",
        "from keras.layers import Multiply #Same for Multiply\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "#Because of the Error : NameError: name 'MaxPool2D' is not defined"
      ],
      "metadata": {
        "id": "05DwbqAxYqp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interestingly, this module indicates and also compares each epoch's results**"
      ],
      "metadata": {
        "id": "OVrdKIawaEWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShowProgress(Callback):\n",
        "    def on_epoch_end(self, epochs, logs=None):\n",
        "        id = np.random.randint(200)\n",
        "        exp = GradCAM()\n",
        "        image = images[id]\n",
        "        mask = masks[id]\n",
        "        pred_mask = self.model.predict(image[np.newaxis,...])\n",
        "        cam = exp.explain(\n",
        "            validation_data=(image[np.newaxis,...], mask),\n",
        "            class_index=1,\n",
        "            model=self.model\n",
        "        )\n",
        "        plt.figure(figsize=(10,5))\n",
        "\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.title(\"Original Mask\")\n",
        "        show_mask_only(mask, cmap='gray')\n",
        "\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        show_mask_only(pred_mask, cmap='gray')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4BxmMhUtNCMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2. Define Residual Recurrent Module**"
      ],
      "metadata": {
        "id": "3Qw5UagkaTnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Residual_block(x, filters, conv_layers=2):\n",
        "    for i in range(conv_layers):\n",
        "        if i == 0:\n",
        "            residual = x\n",
        "            x = Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "        else:\n",
        "            residual = x\n",
        "            x = Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Add()([residual, x])\n",
        "            x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def Recurrent_block(x, filters, conv_layers=1):  # Update conv_layers to 1 for one recurrent block\n",
        "    for i in range(conv_layers):\n",
        "        if i == 0:\n",
        "            x = Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "        else:\n",
        "            residual = x\n",
        "            x = Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Add()([residual, x])\n",
        "            x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def RRCNN_block(x, filters, conv_layers=2):\n",
        "    x1 = Conv2D(filters, kernel_size=(1, 1), strides=1, padding='same')(x)\n",
        "    x2 = Recurrent_block(x1, filters, conv_layers)  # Use Recurrent_block for the first block\n",
        "    x3 = Residual_block(x2, filters, conv_layers)  # Use Residual_block for the second block\n",
        "    out = Add()([x1, x3])\n",
        "    return out"
      ],
      "metadata": {
        "id": "ileVlrRTj7nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3. Define Squeeze-and-Excitation Mechanism and merge SE+RECURRENT+RESIDUAL**"
      ],
      "metadata": {
        "id": "lgj08xdjacye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4. Define the final Architecture of the proposed Algorithm**"
      ],
      "metadata": {
        "id": "ciTkMEVlatq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import keras\n",
        "from keras import backend, optimizers\n",
        "from tensorflow.keras.utils import normalize\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "\n",
        "\n",
        "# spatial squeeze by mean and channel excitation\n",
        "\n",
        "\n",
        "def cse_block(prevlayer, prefix):\n",
        "    mean = Lambda(lambda xin: K.mean(xin, axis=[1, 2]))(prevlayer)  # H W\n",
        "    # K.int_shape() Returns the shape of tensor or variable as a tuple of int or None entries\n",
        "    lin1 = Dense(K.int_shape(prevlayer)[\n",
        "                 3] // 2, name=prefix + 'cse_lin1', activation='relu')(mean)\n",
        "    lin2 = Dense(K.int_shape(prevlayer)[\n",
        "                 3], name=prefix + 'cse_lin2', activation='sigmoid')(lin1)\n",
        "    x = Multiply()([prevlayer, lin2])\n",
        "    return x\n",
        "\n",
        "# channel squeeze and spatial excitation\n",
        "\n",
        "\n",
        "def sse_block(prevlayer, prefix):\n",
        "    # Bug? Should be 1 here?\n",
        "    conv = Conv2D(K.int_shape(prevlayer)[3], (1, 1), padding=\"same\", kernel_initializer=\"he_normal\",\n",
        "                  activation='sigmoid', strides=(1, 1),\n",
        "                  name=prefix + \"_conv\")(prevlayer)\n",
        "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
        "    return conv\n",
        "\n",
        "# concurrent spatial and channel squeeze and channel excitation\n",
        "\n",
        "def csse_block(x, prefix):\n",
        "    cse = cse_block(x, prefix)\n",
        "    sse = sse_block(x, prefix)\n",
        "    x = Add(name=prefix + \"_csse_mul\")([cse, sse])\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def Residual_block(x, filters, conv_layers=2):\n",
        "    for i in range(conv_layers):\n",
        "        if i == 0:\n",
        "            residual = x\n",
        "            x = Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "        else:\n",
        "            residual = x\n",
        "            x = Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Add()([residual, x])\n",
        "            x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def Recurrent_block(x, filters, conv_layers=1):  # Update conv_layers to 1 for one recurrent block\n",
        "    for i in range(conv_layers):\n",
        "        if i == 0:\n",
        "            x = Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "        else:\n",
        "            residual = x\n",
        "            x = Conv2D(filters, kernel_size=(3, 3), strides=1, padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Add()([residual, x])\n",
        "            x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def RRCNN_block(x, filters, conv_layers=2):\n",
        "    x1 = Conv2D(filters, kernel_size=(1, 1), strides=1, padding='same')(x)\n",
        "    x2 = Recurrent_block(x1, filters, conv_layers)  # Use Recurrent_block for the first block\n",
        "    x3 = Residual_block(x2, filters, conv_layers)  # Use Residual_block for the second block\n",
        "    out = Add()([x1, x3])\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Feature Pyramid Model\n",
        "def Feature_Pyr_R2_unet(input_shape = (256,256,3), nClasses=1, dropout_rate=0.0, batch_norm=True):\n",
        "    # encoder\n",
        "\n",
        "    #inputs = Input(shape=(width, height, input_channels))\n",
        "    conv_layers=2\n",
        "    filters=14\n",
        "    UP_SAMP_SIZE =2\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "    conv1 = RRCNN_block(inputs, filters, conv_layers=conv_layers) # (224,224,14)\n",
        "    csse1 = csse_block(conv1, prefix=\"csse1\")\n",
        "    pool1 = MaxPooling2D((2, 2))(csse1) # (112,112,14)\n",
        "    #pool1 = AveragePooling2D((2, 2))(conv1)\n",
        "    conv2 = RRCNN_block(pool1, filters * 2, conv_layers=conv_layers) # (112,112,28)\n",
        "    csse2 = csse_block(conv2, prefix=\"csse2\")\n",
        "    pool2 = MaxPooling2D((2, 2))(csse2) # (56,56,28)\n",
        "    #pool2 = AveragePooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = RRCNN_block(pool2, filters * 4, conv_layers=conv_layers) # (56,56,56)\n",
        "    csse3 = csse_block(conv3, prefix=\"csse3\")\n",
        "    pool3 = MaxPooling2D((2, 2))(csse3) # (28,28,56)\n",
        "    #pool3 = AveragePooling2D((2, 2))(conv3)\n",
        "\n",
        "    conv4 = RRCNN_block(pool3, filters * 8, conv_layers=conv_layers)  # (28,28,112)\n",
        "    csse4 = csse_block(conv4, prefix=\"csse4\")\n",
        "    pool4 = MaxPooling2D((2, 2))(csse4)  # (14,14,112)\n",
        "    #pool4 = AveragePooling2D((2, 2))(conv4)\n",
        "\n",
        "    conv5 = RRCNN_block(pool4, filters * 16, conv_layers=conv_layers) # (14,14,224)\n",
        "    csse5 = csse_block(conv5, prefix=\"csse5\")\n",
        "    conv6=  RRCNN_block(csse5, filters * 16, conv_layers=conv_layers) # (14,14,224)\n",
        "    csse6 = csse_block(conv6, prefix=\"csse6\")\n",
        "\n",
        "    conv7=  RRCNN_block(csse6, filters * 8, conv_layers=conv_layers)  # (14,14,112)\n",
        "    csse7 = csse_block(conv7, prefix=\"csse7\")\n",
        "    net_up1 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\",interpolation='bilinear')(csse7)  # (28,28,112)\n",
        "    new_concat1 = layers.concatenate([net_up1,csse4], axis=3)\t # (28,28,112)\n",
        "    conv8=  RRCNN_block(new_concat1, filters * 8, conv_layers=conv_layers)  # (28,28,112)\n",
        "    conv9=  RRCNN_block(conv8, filters * 8, conv_layers=conv_layers)   # (28,28,112)\n",
        "\n",
        "    conv10 = RRCNN_block(conv9, filters * 4, conv_layers=conv_layers)   # (28,28,56)\n",
        "    net_up2 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\",interpolation='bilinear')(conv10) # (56,56,56)\n",
        "    new_concat2 = layers.concatenate([net_up2,csse3], axis=3)\n",
        "    conv11 = RRCNN_block(new_concat2, filters * 4, conv_layers=conv_layers)  #(56,56,56)\n",
        "    conv12 = RRCNN_block(conv11, filters * 4, conv_layers=conv_layers)   #(56,56,56)\n",
        "\n",
        "\n",
        "    conv13 = RRCNN_block(conv12, filters * 2, conv_layers=conv_layers)   # (56,56,28)\n",
        "    net_up3 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\",interpolation='bilinear')(conv13) # (112,112,28)\n",
        "    new_concat3 = layers.concatenate([net_up3,csse2], axis=3)\n",
        "    conv14 = RRCNN_block(new_concat3, filters * 2, conv_layers=conv_layers)  #(112,112,28)\n",
        "    conv15 = RRCNN_block(conv14, filters * 2, conv_layers=conv_layers)   #(112,112,28)\n",
        "\n",
        "    conv16 = RRCNN_block(conv15, filters , conv_layers=conv_layers)   # (112,112,14)\n",
        "\n",
        "    # Feature Stacking\n",
        "    pyr_layer1 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\",interpolation='bilinear')(conv16)\n",
        "    pyr_layer2= layers.UpSampling2D(size=(UP_SAMP_SIZE*2, UP_SAMP_SIZE*2), data_format=\"channels_last\",interpolation='bilinear')(conv13)\n",
        "    pyr_layer3= layers.UpSampling2D(size=(UP_SAMP_SIZE*4, UP_SAMP_SIZE*4), data_format=\"channels_last\",interpolation='bilinear')(conv10)\n",
        "    pyr_layer4= layers.UpSampling2D(size=(UP_SAMP_SIZE*8, UP_SAMP_SIZE*8), data_format=\"channels_last\",interpolation='bilinear')(csse7)\n",
        "\n",
        "\n",
        "\n",
        "    concat1 = layers.concatenate([pyr_layer1,pyr_layer2,pyr_layer3,pyr_layer4], axis=3)\n",
        "    conv17 = RRCNN_block(concat1, filters*4, conv_layers=conv_layers)  #(224,224,56)\n",
        "    conv18 = RRCNN_block(conv17, filters, conv_layers=conv_layers)   #(224,224,14)\n",
        "\n",
        "    conv_final = layers.Conv2D(nClasses, kernel_size=(1,1))(conv18)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    conv_final = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    # Model integration\n",
        "    model = models.Model(inputs, conv_final, name=\"Feature_Pyr_R2_unet\")\n",
        "    return model\n",
        "\n",
        "def final_model(input_shape):\n",
        "    final_unet_model = Feature_Pyr_R2_unet(input_shape=(input_shape[0], input_shape[1], 3))\n",
        "    return final_unet_model\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "model = final_model(input_shape = (256,256,3))\n",
        "model.summary()\n",
        "\n",
        "# Callbacks\n",
        "cb = [\n",
        "    # EarlyStopping(patience=3, restore_best_weight=True), # With Segmentation I trust on eyes rather than on metrics\n",
        "    ModelCheckpoint(\"AttentionCustomUNet.keras\", save_best_only=True),\n",
        "    ShowProgress()\n",
        "]"
      ],
      "metadata": {
        "id": "sGgjfqTbHgfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.5. Define Performance Metrics and Compile the model**"
      ],
      "metadata": {
        "id": "e0q62zDAa2ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "from keras.metrics import MeanIoU     #Because of the Error NameError: name 'MeanIoU' is not defined"
      ],
      "metadata": {
        "id": "8rlqBB2mY3wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1e-15\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return dice\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy', dice_coeff, tf.keras.metrics.MeanIoU(num_classes=2, name='IoU')]\n",
        ")"
      ],
      "metadata": {
        "id": "qhO7sHWRbmAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tf_explain.core.grad_cam import GradCAM\n",
        "#Because of the Error NameError: name 'GradCAM' is not defined"
      ],
      "metadata": {
        "id": "N7Q9OPe4eOqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6. Start the Process of training"
      ],
      "metadata": {
        "id": "IYo7PIFqa-n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Config Training\n",
        "BATCH_SIZE = 32\n",
        "SPE = len(X_train) // BATCH_SIZE\n",
        "\n",
        "# Training\n",
        "results = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=61, # 15 will be enough for a good Model for better model go with 20+\n",
        "    steps_per_epoch=SPE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=cb\n",
        ")"
      ],
      "metadata": {
        "id": "F0nAGQCwH05x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, iou, val_loss, val_accuracy, val_iou = results.history.values()"
      ],
      "metadata": {
        "id": "YfkJLI2XcST-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def get_mask_box(mask):\n",
        "    img = np.uint8(mask[0, :, :, 0] * 255)\n",
        "\n",
        "    _, binary = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        color = (0, 255, 0)\n",
        "        cv2.rectangle(img_bgr, (x, y), (x + w, y + h), color, 2)\n",
        "\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 0.5\n",
        "        thickness = 1\n",
        "        text_height = f'Height: {h}'\n",
        "        text_width = f'Width: {w}'\n",
        "        text_height_size = cv2.getTextSize(text_height, font, font_scale, thickness)[0]\n",
        "        text_width_size = cv2.getTextSize(text_width, font, font_scale, thickness)[0]\n",
        "        cv2.putText(img_bgr, text_height, (x, y - text_height_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)\n",
        "        cv2.putText(img_bgr, text_width, (x + w - text_width_size[0], y + h + text_width_size[1]), font, font_scale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "    plt.imshow(img_bgr,cmap = None)\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "USybWny7caAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Results**"
      ],
      "metadata": {
        "id": "8zwYqYBDbDLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1. Show the predicted masks and compare them to the original ones**"
      ],
      "metadata": {
        "id": "cm7hgaiubF4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,25))\n",
        "n=0\n",
        "for i in range(1,(5*3)+1):\n",
        "    plt.subplot(5,3,i)\n",
        "    if n==0:\n",
        "        id = np.random.randint(len(images))\n",
        "        image = images[id]\n",
        "        mask = masks[id]\n",
        "        pred_mask = model.predict(image[np.newaxis,...])\n",
        "\n",
        "        plt.title(\"Original Mask\")\n",
        "        show_mask(image, mask)\n",
        "        n+=1\n",
        "    elif n==1:\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        show_mask(image, pred_mask)\n",
        "        n+=1\n",
        "    elif n==2:\n",
        "        pred_mask = (pred_mask>0.5).astype('float')\n",
        "        plt.title(\"Processed Mask\")\n",
        "        show_mask(image, pred_mask)\n",
        "        n=0\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fjdY5r9IcbHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,25))\n",
        "n=0\n",
        "for i in range(1,(5*3)+1):\n",
        "    plt.subplot(5,3,i)\n",
        "    if n==0:\n",
        "        id = np.random.randint(len(images))\n",
        "        image = images[id]\n",
        "        mask = masks[id]\n",
        "        pred_mask = model.predict(image[np.newaxis,...])\n",
        "\n",
        "        plt.title(\"Original Mask\")\n",
        "        show_mask(image, mask)\n",
        "        n+=1\n",
        "    elif n==1:\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        show_mask(image, pred_mask)\n",
        "        n+=1\n",
        "    elif n==2:\n",
        "        pred_mask = (pred_mask>0.5).astype('float')\n",
        "        plt.title(\"Processed Mask\")\n",
        "#         show_mask(image, pred_mask)\n",
        "        get_mask_box(pred_mask)\n",
        "        n=0\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-CFrt9Idcu9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2. Just a Sample (if you have anything especific in mind)**"
      ],
      "metadata": {
        "id": "lSO_R52YbOZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = 12\n",
        "image = images[id]\n",
        "mask = model.predict(image[np.newaxis,...])\n",
        "get_mask_box(mask)"
      ],
      "metadata": {
        "id": "z8Ru53MmcvXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3. And the RESULTS...**"
      ],
      "metadata": {
        "id": "MG2fQFYabW3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# assume y_true is the true binary mask and y_pred is the predicted mask\n",
        "# both have shape (num_samples, height, width, num_channels)\n",
        "y_true = y_val\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# threshold the predicted mask to convert to binary values\n",
        "y_true_bool = (y_true > 0.5).astype(bool)\n",
        "cm = confusion_matrix(y_true_bool.flatten(), y_pred_thresh.flatten())\n",
        "cr = classification_report(y_true_bool.flatten(), y_pred_thresh.flatten())\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(cm)\n",
        "print(\"Classification report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "vqpzFhHLcxc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Model Loss (Training Loss and Validation Loss)\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('2D U-Net Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.legend(['Training Loss' , 'Validation Loss'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UNZoM2H-CH3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Model Accuracy (Training Accuracy and Validation Accuracy)\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('2D U-Net Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.legend(['Training Loss' , 'Validation Loss'], loc = 'lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_lQNwlQzCJPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Model Dice Similarity Coefficient\n",
        "\n",
        "plt.plot(hist.history['dice_coef1'])\n",
        "plt.plot(hist.history['val_dice_coef1'])\n",
        "plt.title('2D Model Dice Similarity Coefficient')\n",
        "plt.ylabel('Dice Similarity Coefficient')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.legend(['Trainining DSC' , 'Validation DSC'], loc = 'lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jr_xbJsSCKhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Intersection over Union\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('2D U-Net Model IoU')\n",
        "plt.ylabel('Intersection over Union')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.legend(['Training IoU' , 'Validation IoU'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WUNwQtULCMhC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}